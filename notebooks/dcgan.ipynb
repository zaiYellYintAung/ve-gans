{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "id": "xNiydKOa0oFk"
      },
      "outputs": [],
      "source": [
        "#project gans"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "from torchvision.utils import save_image\n",
        "import numpy as np\n",
        "\n",
        "# Check if GPU is available and set the device accordingly\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "SCS7gRJQ0tyS"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_sample_image(generator, noise_dim):\n",
        "    \"\"\"\n",
        "    Save sample 100 images\n",
        "    \"\"\"\n",
        "    noise = torch.randn(100, noise_dim).to(device)\n",
        "    generated_images = generator(noise).view(100, 28, 28)  # (100, 28, 28)\n",
        "    result = generated_images.cpu().data.numpy()\n",
        "    img = np.zeros([280, 280])\n",
        "    for j in range(10):\n",
        "        img[j * 28:(j + 1) * 28] = np.concatenate([x for x in result[j * 10:(j + 1) * 10]], axis=-1)\n",
        "    return img"
      ],
      "metadata": {
        "id": "sacBbf_LwZx-"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, in_channels=1, num_classes=1):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, 512, 3, stride=2, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.LeakyReLU(0.2),\n",
        "\n",
        "            nn.Conv2d(512, 256, 3, stride=2, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.LeakyReLU(0.2),\n",
        "\n",
        "            nn.Conv2d(256, 128, 3, stride=2, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.AvgPool2d(4),\n",
        "        )\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(128, 1),\n",
        "            nn.Sigmoid(),\n",
        "        )\n",
        "\n",
        "    def forward(self, x, y=False):\n",
        "        features = self.conv(x)\n",
        "        features = features.view(features.size(0), -1)\n",
        "        output = self.fc(features)\n",
        "        return output\n"
      ],
      "metadata": {
        "id": "e9n-wD7dwZ7n"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Generator(nn.Module):\n",
        "    def __init__(self, input_size=100, num_classes=784):\n",
        "        super(Generator, self).__init__()\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(input_size, 4 * 4 * 512),\n",
        "            nn.ReLU(),\n",
        "        )\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.ConvTranspose2d(512, 256, 3, stride=2, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(),\n",
        "\n",
        "            nn.ConvTranspose2d(256, 128, 4, stride=2, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(),\n",
        "\n",
        "            nn.ConvTranspose2d(128, 1, 4, stride=2, padding=1, bias=False),\n",
        "            nn.Tanh(),\n",
        "        )\n",
        "\n",
        "    def forward(self, x, y=None):\n",
        "        x = x.view(x.size(0), -1)\n",
        "        features = self.fc(x)\n",
        "        features = features.view(features.size(0), 512, 4, 4)\n",
        "        output = self.conv(features)\n",
        "        return output\n"
      ],
      "metadata": {
        "id": "_8-E4605wZ-e"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Instantiate the Generator and Discriminator\n",
        "generator = Generator().to(device)\n",
        "discriminator = Discriminator().to(device)"
      ],
      "metadata": {
        "id": "OSDpsaYBypVA"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([transforms.ToTensor(),\n",
        "                                transforms.Normalize(mean=[0.5],\n",
        "                                std=[0.5])]\n",
        ")"
      ],
      "metadata": {
        "id": "yQ8QdKuCz2_a"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 64\n",
        "\n",
        "data = torchvision.datasets.FashionMNIST(root='./data/', train=True, transform=transform, download=True)\n",
        "data_loader = DataLoader(dataset=data, batch_size=batch_size, shuffle=True, drop_last=True)\n",
        "\n",
        "loss_fn = nn.BCELoss()\n",
        "d_optimizer = torch.optim.Adam(discriminator.parameters(), lr=0.001, betas=(0.5, 0.999))\n",
        "g_optimizer = torch.optim.Adam(generator.parameters(), lr=0.001, betas=(0.5, 0.999))\n"
      ],
      "metadata": {
        "id": "8mOTuoih-3ep"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_epochs = 50\n",
        "step = 0\n",
        "n_critic = 1\n",
        "n_noise = 100\n",
        "\n",
        "d_labels = torch.ones([batch_size, 1]).to(device)\n",
        "d_fakes = torch.zeros([batch_size, 1]).to(device)"
      ],
      "metadata": {
        "id": "kHJ0B3mk-4Bt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training loop\n",
        "for epoch in range(max_epochs):\n",
        "    for idx, (images, labels) in enumerate(data_loader):\n",
        "        real_images = images.to(device)\n",
        "\n",
        "        # Discriminator training\n",
        "        real_outputs = discriminator(real_images)\n",
        "        d_real_loss = loss_fn(real_outputs, d_labels)\n",
        "\n",
        "        fake_noise = torch.randn(batch_size, n_noise).to(device)\n",
        "        fake_images = generator(fake_noise)\n",
        "        fake_outputs = discriminator(fake_images.detach())\n",
        "        d_fake_loss = loss_fn(fake_outputs, d_fakes)\n",
        "\n",
        "        d_loss = d_real_loss + d_fake_loss\n",
        "\n",
        "        discriminator.zero_grad()\n",
        "        d_loss.backward()\n",
        "        d_optimizer.step()\n",
        "\n",
        "        # Generator training (every n_critic iterations)\n",
        "        if step % n_critic == 0:\n",
        "            fake_outputs = discriminator(fake_images)\n",
        "            g_loss = loss_fn(fake_outputs, d_labels)\n",
        "\n",
        "            generator.zero_grad()\n",
        "            discriminator.zero_grad()\n",
        "            g_loss.backward()\n",
        "            g_optimizer.step()\n",
        "\n",
        "            if step % 500 == 0:\n",
        "                print('Epoch: {}/{}, Step: {}, D Loss: {}, G Loss: {}'.format(epoch, max_epochs, step, d_loss.item(), g_loss.item()))\n",
        "\n",
        "            if step % 1000 == 0:\n",
        "                generator.eval()\n",
        "                img = get_sample_image(generator, n_noise)\n",
        "                # imsave('samples/{}_step{}.jpg'.format(MODEL_NAME, str(step).zfill(3)), img, cmap='gray')\n",
        "                generator.train()\n",
        "            step += 1"
      ],
      "metadata": {
        "id": "1V9EfSBD-8E9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# neeed to test"
      ],
      "metadata": {
        "id": "1g4ATYOD-9LY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UPye6Ktu--Ph"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}